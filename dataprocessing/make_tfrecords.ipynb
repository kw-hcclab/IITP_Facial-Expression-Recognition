{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import data_process\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "눈썹들어올리기+1 폴더 작업중: 100%|██████████| 55/55 [00:00<00:00, 144.84it/s]\n",
      "두눈감기+2 폴더 작업중: 100%|██████████| 69/69 [00:00<00:00, 193.13it/s]\n",
      "두눈크게뜨기+3 폴더 작업중: 100%|██████████| 79/79 [00:00<00:00, 125.65it/s]\n",
      "미소짓기+4 폴더 작업중: 100%|██████████| 48/48 [00:00<00:00, 173.59it/s]\n",
      "입벌리기+5 폴더 작업중: 100%|██████████| 57/57 [00:00<00:00, 137.02it/s]\n",
      "입술오므리기+6 폴더 작업중: 100%|██████████| 63/63 [00:00<00:00, 144.75it/s]\n",
      "중립+0 폴더 작업중: 100%|██████████| 56/56 [00:00<00:00, 172.33it/s]\n",
      "중립2+0 폴더 작업중: 100%|██████████| 33/33 [00:00<00:00, 194.05it/s]\n",
      "이미지를 tfrecord에 저장중: 100%|██████████| 452/452 [00:00<00:00, 521.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 갯수:  452\n",
      "[5, 1, 3, 2, 6, 4, 2, 6, 6, 3, 2, 2, 2, 2, 4, 1, 3, 0, 1, 3, 3, 5, 2, 2, 0, 2, 2, 4, 5, 6, 6, 5, 5, 3, 6, 3, 1, 3, 5, 3, 0, 2, 0, 1, 1, 0, 3, 3, 0, 2, 5, 1, 5, 6, 3, 4, 5, 0, 2, 1, 1, 5, 6, 3, 6, 3, 1, 6, 0, 6, 3, 2, 1, 4, 5, 4, 0, 4, 0, 6, 6, 0, 3, 5, 6, 1, 1, 0, 5, 6, 4, 4, 5, 3, 6, 3, 4, 2, 3, 0, 3, 2, 3, 4, 0, 2, 0, 4, 5, 4, 4, 6, 4, 2, 3, 5, 6, 5, 3, 4, 0, 4, 1, 0, 6, 6, 4, 6, 6, 3, 5, 5, 3, 6, 6, 1, 3, 6, 5, 5, 4, 1, 0, 5, 3, 2, 3, 0, 5, 0, 5, 6, 2, 4, 4, 2, 3, 3, 2, 0, 4, 4, 0, 1, 5, 0, 3, 2, 5, 5, 3, 0, 3, 2, 0, 1, 3, 4, 2, 2, 3, 1, 6, 5, 0, 1, 0, 1, 5, 1, 2, 0, 3, 1, 2, 3, 3, 4, 4, 3, 0, 0, 1, 4, 6, 0, 3, 0, 2, 3, 2, 5, 2, 0, 4, 5, 0, 6, 1, 3, 6, 4, 4, 0, 5, 2, 3, 5, 3, 6, 3, 0, 5, 0, 6, 6, 0, 0, 0, 5, 5, 0, 3, 0, 0, 0, 0, 3, 5, 3, 3, 1, 3, 6, 3, 0, 3, 3, 0, 2, 3, 2, 1, 1, 1, 2, 0, 1, 2, 4, 3, 5, 6, 0, 2, 0, 2, 1, 2, 5, 6, 4, 0, 0, 3, 5, 2, 3, 2, 5, 4, 6, 4, 0, 4, 5, 6, 5, 2, 1, 0, 3, 5, 2, 6, 3, 4, 3, 4, 2, 4, 2, 1, 2, 1, 6, 0, 2, 4, 6, 3, 0, 2, 2, 0, 6, 3, 0, 6, 1, 5, 0, 6, 5, 0, 0, 2, 6, 1, 6, 3, 2, 6, 4, 3, 0, 6, 3, 0, 0, 0, 6, 2, 1, 3, 6, 5, 1, 5, 4, 4, 1, 2, 4, 3, 0, 1, 0, 2, 0, 3, 2, 1, 0, 0, 6, 2, 2, 2, 0, 0, 0, 5, 6, 6, 5, 0, 5, 3, 1, 4, 2, 0, 0, 0, 2, 4, 6, 6, 2, 1, 1, 2, 6, 5, 0, 5, 0, 1, 3, 6, 6, 0, 0, 2, 5, 3, 0, 1, 3, 6, 4, 1, 1, 3, 0, 3, 6, 5, 2, 1, 6, 1, 4, 2, 0, 3, 1, 0, 5, 1, 2, 0, 3, 0, 1, 6, 2, 3, 2, 1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_process.data_to_tfrecord(imagepath='../data/image_mobilenet/', outputpath='../data/face_data_multi.tfrecord', mode='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _filenames = '../data/face_data_7.tfrecord'\n",
    "# raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "# raw_dataset\n",
    "# # Create a dictionary describing the features.\n",
    "# image_feature_description = {\n",
    "#     'image': tf.io.FixedLenFeature([], tf.string),    \n",
    "#     'class': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'landmark_points': tf.io.FixedLenFeature([], tf.float32),    \n",
    "# }\n",
    "\n",
    "# def _parse_image_function(example_proto): \n",
    "#   # Parse the input tf.train.Example proto using the dictionary above.  \n",
    "#   return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "# parsed_image_dataset = raw_dataset.map(_parse_image_function)\n",
    "# parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_features in parsed_image_dataset:\n",
    "#     print(image_features)\n",
    "#     image_raw = image_features['class'].numpy()\n",
    "# print(image_raw)\n",
    "# # display.display(display.Image(data=image_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def landmark_tfrecord_reader(example):\n",
    "    feature_description = {\"image\": tf.io.VarLenFeature(dtype=tf.string),\n",
    "                           \"class\": tf.io.VarLenFeature(dtype=tf.int64),\n",
    "                           \"landmark_points\": tf.io.VarLenFeature(dtype=tf.float32)}\n",
    "\n",
    "    inputs = {}\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    image_raw = tf.sparse.to_dense(example[\"image\"])[0]\n",
    "    inputs['image'] = tf.io.decode_png(image_raw, channels=3)\n",
    "    image_class = tf.sparse.to_dense(example[\"class\"])\n",
    "    inputs['image_landmarks'] = tf.cast(tf.sparse.to_dense(example[\"landmark_points\"]), tf.float32)\n",
    "    return inputs, image_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_scaling(x, y):\n",
    "    x['image'] = tf.cast(x['image'], tf.float32) / 255.\n",
    "    # x 480pixel, y 640pixel\n",
    "    x['image_landmarks'] = tf.cast(x['image_landmarks'], tf.float32)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = '../data/face_data_multi.tfrecord'\n",
    "ds = tf.data.TFRecordDataset(filenames).map(landmark_tfrecord_reader)\n",
    "ds = ds.map(image_scaling).batch(32)\n",
    "ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lds = list(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 266), dtype=float32, numpy=\n",
       "array([[0.5127119 , 0.05833333, 0.58474576, ..., 0.62916666, 0.75      ,\n",
       "        0.64166665],\n",
       "       [0.5032258 , 0.05483871, 0.56774193, ..., 0.63548386, 0.716129  ,\n",
       "        0.63870966],\n",
       "       [0.5064516 , 0.05483871, 0.57741934, ..., 0.65806454, 0.7064516 ,\n",
       "        0.66129035],\n",
       "       ...,\n",
       "       [0.5046729 , 0.05164319, 0.57476634, ..., 0.62910795, 0.71028036,\n",
       "        0.65258217],\n",
       "       [0.5092593 , 0.05381166, 0.5787037 , ..., 0.62780267, 0.7268519 ,\n",
       "        0.6367713 ],\n",
       "       [0.51229507, 0.08196721, 0.58196723, ..., 0.6147541 , 0.7336066 ,\n",
       "        0.63114756]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lds[0][0]['image_landmarks']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tfface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e318f884811f55877d06bbc5456a4670ca1397bb6e20c4ae81dc4f96f0847c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
